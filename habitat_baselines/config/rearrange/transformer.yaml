VERBOSE: False
BASE_TASK_CONFIG_PATH: configs/tasks/rearrange/composite.yaml
TRAINER_NAME: "transformer"
ENV_NAME: "RearrangeRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ["disk"]
TENSORBOARD_DIR: "tb"
VIDEO_DIR: "video_dir"
VIDEO_FPS: 30
VIDEO_RENDER_TOP_DOWN: False
VIDEO_RENDER_ALL_INFO: True
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "data/new_checkpoints"
NUM_ENVIRONMENTS: 1
WRITER_TYPE: 'tb'
# Visual sensors to include
SENSORS: ["HEAD_DEPTH_SENSOR"]
CHECKPOINT_FOLDER: "data/new_checkpoints"
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 1.0e8
LOG_INTERVAL: 1
NUM_CHECKPOINTS: -1
CHECKPOINT_INTERVAL: 10
FORCE_TORCH_SINGLE_THREADED: True
EVAL_KEYS_TO_INCLUDE_IN_NAME: ['reward', 'force', 'success']

RL:
  POLICY:
      name: "TransformerResNetPolicy"
      action_distribution_type: "gaussian"
      include_visual_keys: ["robot_head_depth"]
      

  REWARD_MEASURE: "composite_reward"
  SUCCESS_MEASURE: "composite_success"
  SUCCESS_REWARD: 100.0
  SLACK_REWARD: -0.01
  GYM_OBS_KEYS: ['obj_start_sensor', 'joint', 'is_holding', 'relative_resting_position']

  TRAJECTORY_DATASET:
    trajectory_dir: "./data/temp_data"
    steps_per_load: 1500
    steps_to_reload: 15000
    trajs_per_file: 10


  TRANSFORMER:
    lr: 1.0E-4
    eps: 1.0E-5
    grad_norm_clip: 0.5
    use_linear_lr_decay: True
    batch_size: 32 # 160
    num_workers: 2




    return_to_go: 140
    
    num_mini_batch: 2
    context_length: 30
    max_episode_step: 400
    model_type: "reward_conditioned"
    n_head: 8
    n_layer: 6
    use_linear_clip_decay: False
    reward_window_size: 50

    use_normalized_advantage: False

    hidden_size: 512

    # Use double buffered sampling, typically helps
    # when environment time is similar or large than
    # policy inference time during rollout generation
    use_double_buffered_sampler: False

    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: NCCL
    # Visual encoder backbone
    pretrained_weights: data/new_checkpoints/ckpt.0.pth #
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True

    # Model parameters
    backbone: resnet18 # resnet18

  

WB:
  PROJECT_NAME: "habitat"
  ENTITY: "haytham-huang"
  RUN_NAME: "nav_pick"
  GROUP: "overfit"
